{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third assignment: Network Robustness\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Use small graphs to write the code\n",
    "\n",
    "1. In the first part, you can use some graphs obtained by using the Networkx library or the library of your choice.\n",
    "2. For each selected graph (max 2 or 3) you can perform different types of attack: turn off nodes at random, turn off the highest degree nodes, those with the highest pagerank, those with the highest betweenness, ...\n",
    "2. After each removal, compute new measures, for example the size of the giant component or the diameter of the network and then plot these measures with respect to node failures. In case of networks of large size, often for the giant component S/N is plotted, e.g., the ratio between the size of the giant component and the size of the network.\n",
    "2. Be careful, some of the functions you will use work only for undirected, connected graphs and therefore you need to instrument your code to work on the entire graph first, and then on the several components after the split of the original graph into smaller clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.io import mmread\n",
    "from scipy import integrate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_random_nodes(G:nx.Graph, num:int=1) -> nx.Graph:\n",
    "    \"\"\"Remove a percentage of random nodes from the graph G and return the resulting graph.\n",
    "\n",
    "    Args:\n",
    "        G: A networkx graph.\n",
    "        num: number of nodes to remove from G.\n",
    "\n",
    "    Returns:\n",
    "        A networkx graph.\n",
    "    \"\"\"\n",
    "    num = 1 if num < 1 else num\n",
    "    if G.number_of_nodes() <= 0:\n",
    "        return nx.Graph()\n",
    "    \n",
    "    prev_nodes = G.number_of_nodes()\n",
    "    if prev_nodes > 0:\n",
    "        # Get random nodes from G\n",
    "        nodes = list(G.nodes)\n",
    "        # random.shuffle(nodes)\n",
    "        if num > len(nodes):\n",
    "            num = len(nodes)\n",
    "        nodes = random.sample(nodes, num)\n",
    "        # remove num nodes from G (if num > len(nodes), remove all nodes)\n",
    "        G.remove_nodes_from(nodes[0:num])\n",
    "    # Return the resulting graph\n",
    "    return G if G.number_of_nodes() != prev_nodes else nx.Graph()\n",
    "\n",
    "def remove_highest_degree_node(G:nx.Graph, num:int=1) -> nx.Graph:\n",
    "    \"\"\"Remove a percentage of nodes with the highest degree from the graph G and return the resulting graph.\n",
    "    \n",
    "    Args:\n",
    "        G: A networkx graph.\n",
    "        num: number of nodes to remove from G.\n",
    "        \n",
    "    Returns:\n",
    "        A networkx graph.\n",
    "    \"\"\"\n",
    "    num = 1 if num < 1 else num\n",
    "    if G.number_of_nodes() <= 0:\n",
    "        return nx.Graph()\n",
    "    \n",
    "    prev_nodes = G.number_of_nodes()\n",
    "    if prev_nodes > 0:\n",
    "        # sort nodes by degree\n",
    "        nodes = sorted(G.degree, key=lambda x: x[1], reverse=True)\n",
    "        # remove num nodes from G (if num > len(nodes), remove all nodes)\n",
    "        if num > len(nodes):\n",
    "            num = len(nodes)\n",
    "        nodes = [node[0] for node in nodes[0:num]]\n",
    "        G.remove_nodes_from(nodes)\n",
    "    # Return the resulting graph\n",
    "    return ( G if G.number_of_nodes() != prev_nodes else nx.Graph() )\n",
    "\n",
    "def remove_highest_betweenness_node(G:nx.Graph, num:int=1) -> nx.Graph:\n",
    "    \"\"\"Remove the node with the highest betweenness centrality from the graph G and return the resulting graph.\n",
    "    \n",
    "    Args:\n",
    "        G: A networkx graph.\n",
    "        num: number of nodes to remove from G.\n",
    "        \n",
    "    Returns:\n",
    "        A networkx graph.\n",
    "    \"\"\"\n",
    "    num = 1 if num < 1 else num\n",
    "    if G.number_of_nodes() <= 0:\n",
    "        return nx.Graph()\n",
    "    \n",
    "    prev_nodes = G.number_of_nodes()\n",
    "    if prev_nodes > 0:\n",
    "        # Get the nodes with highest betweenness centrality from G\n",
    "        nodes = sorted(nx.betweenness_centrality(G).items(), key=lambda x: x[1], reverse=True)\n",
    "        if num > len(nodes):\n",
    "            num = len(nodes)\n",
    "        # Remove num nodes from G\n",
    "        nodes = [node[0] for node in nodes[0:num]]\n",
    "        G.remove_nodes_from(nodes)\n",
    "        # Return the resulting graph\n",
    "    return G if G.number_of_nodes() != prev_nodes else nx.Graph()\n",
    "\n",
    "def remove_highest_pagerank_node(G:nx.Graph, num:int=1) -> nx.Graph:\n",
    "    \"\"\"Remove the node with the highest PageRank from the graph G and return the resulting graph.\n",
    "    \n",
    "    Args:\n",
    "        G: A networkx graph.\n",
    "        num: number of nodes to remove from G.\n",
    "        \n",
    "    Returns:\n",
    "        A networkx graph.\n",
    "    \"\"\"\n",
    "    num = 1 if num < 1 else num\n",
    "    if G.number_of_nodes() <= 0:\n",
    "        return nx.Graph()\n",
    "    \n",
    "    prev_nodes = G.number_of_nodes()\n",
    "    if prev_nodes > 0:\n",
    "        # Get the nodes with the highest PageRank from G\n",
    "        nodes = sorted(nx.pagerank(G).items(), key=lambda x: x[1], reverse=True)\n",
    "        # Remove the node from G\n",
    "        if num > len(nodes):\n",
    "            num = len(nodes)\n",
    "        nodes = [node[0] for node in nodes[0:num]]\n",
    "        G.remove_nodes_from(nodes)\n",
    "    # Return the resulting graph\n",
    "    return G\n",
    "\n",
    "def remove_highest_closeness_node(G: nx.Graph, num:int=1) -> nx.Graph:\n",
    "    \"\"\"Remove the node with the highest closeness centrality from the graph G and return the resulting graph.\n",
    "    \n",
    "    Args:\n",
    "        G: A networkx graph.\n",
    "        num: number of nodes to remove from G.\n",
    "        \n",
    "    Returns:\n",
    "        A networkx graph.\n",
    "    \"\"\"\n",
    "    num = 1 if num < 1 else num\n",
    "    if G.number_of_nodes() <= 0:\n",
    "        return nx.Graph()\n",
    "    \n",
    "    prev_nodes = G.number_of_nodes()\n",
    "    if prev_nodes > 0:\n",
    "        # Get the node with the highest closeness centrality from G\n",
    "        node = max(nx.closeness_centrality(G).items(), key=lambda x: x[1])[0]\n",
    "        # Remove the node from G\n",
    "        G.remove_node(node)\n",
    "    # Return the resulting graph\n",
    "    return G if G.number_of_nodes() != prev_nodes else nx.Graph()\n",
    "\n",
    "def get_lcc(G: nx.Graph) -> nx.Graph:\n",
    "    \"\"\"Get the largest connected component of the graph G and return the resulting graph.\n",
    "    \n",
    "    Args:\n",
    "        G: A networkx graph.\n",
    "        \n",
    "    Returns:\n",
    "        A networkx graph.\n",
    "    \"\"\"\n",
    "    # Get the largest connected component from G\n",
    "    largest_comp = max(nx.connected_components(G), key=len) if len(G) > 0 else set()\n",
    "    # Return the resulting graph\n",
    "    return nx.Graph(G.subgraph(largest_comp))\n",
    "\n",
    "def get_lcc_size(G: nx.Graph) -> int:\n",
    "    \"\"\"Deprecated. Use get_lcc instead.\"\"\"\n",
    "    raise Exception(\"Deprecated. Use get_lcc instead.\")\n",
    "\n",
    "def get_diameter(G: nx.Graph) -> int:\n",
    "    \"\"\"Get the diameter of the graph G and return the resulting diameter.\n",
    "    \n",
    "    Args:\n",
    "        G: A networkx graph.\n",
    "        \n",
    "    Returns:\n",
    "        An integer.\n",
    "    \"\"\"\n",
    "    if len(G) == 0:\n",
    "        return 0\n",
    "    if not nx.is_connected(G):\n",
    "        G = G.subgraph(max(nx.connected_components(G), key=len))\n",
    "    return nx.diameter(G) if len(G) > 0 else 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Graph n=100 p=0,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g1\n",
      "5300\n",
      "5247\n",
      "5194\n",
      "5136\n",
      "5079\n",
      "5021\n",
      "4954\n",
      "4896\n",
      "4835\n",
      "4756\n",
      "4691\n",
      "4629\n",
      "4569\n",
      "4509\n",
      "4434\n",
      "4370\n",
      "4274\n",
      "4204\n",
      "4122\n",
      "4037\n",
      "3928\n",
      "3808\n",
      "3714\n",
      "3642\n",
      "3517\n",
      "3370\n",
      "3290\n",
      "2749\n",
      "2562\n",
      "2427\n",
      "1799\n",
      "1102\n",
      "516\n",
      "164\n",
      "g2\n",
      "5300\n",
      "5247\n",
      "5131\n",
      "5041\n",
      "4925\n",
      "4761\n",
      "4670\n",
      "4457\n",
      "4252\n",
      "4047\n",
      "3822\n",
      "2864\n",
      "2609\n",
      "2403\n",
      "1884\n",
      "695\n",
      "17\n",
      "g3\n",
      "5300\n",
      "5247\n",
      "5192\n",
      "5130\n",
      "5027\n",
      "3040\n",
      "2979\n",
      "2894\n",
      "1534\n",
      "1165\n",
      "538\n",
      "356\n",
      "28\n",
      "g4\n",
      "5300\n",
      "5299\n",
      "5296\n",
      "5294\n",
      "5293\n",
      "5292\n",
      "5291\n",
      "5290\n",
      "5289\n",
      "5288\n",
      "5287\n",
      "5284\n",
      "5283\n",
      "5282\n",
      "5281\n",
      "5279\n",
      "5270\n",
      "5267\n",
      "5259\n",
      "5258\n",
      "5257\n",
      "5256\n",
      "5255\n",
      "5240\n",
      "5239\n",
      "5227\n",
      "5226\n",
      "5225\n",
      "5216\n",
      "5215\n",
      "5211\n",
      "5210\n",
      "5205\n",
      "5204\n",
      "5198\n",
      "5196\n",
      "5192\n",
      "5189\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 122\u001b[0m\n\u001b[1;32m    119\u001b[0m     plt\u001b[39m.\u001b[39mlegend()\n\u001b[1;32m    120\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m--> 122\u001b[0m attack(G, \u001b[39m0.01\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[3], line 74\u001b[0m, in \u001b[0;36mattack\u001b[0;34m(G, percentage)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mwhile\u001b[39;00m g4\u001b[39m.\u001b[39mnumber_of_nodes() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     73\u001b[0m     \u001b[39mprint\u001b[39m(g4\u001b[39m.\u001b[39mnumber_of_nodes())\n\u001b[0;32m---> 74\u001b[0m     g4 \u001b[39m=\u001b[39m get_lcc(g4)\n\u001b[1;32m     75\u001b[0m     l4\u001b[39m.\u001b[39mappend( g4\u001b[39m.\u001b[39mnumber_of_nodes() )\n\u001b[1;32m     76\u001b[0m     d4\u001b[39m.\u001b[39mappend( get_diameter(g4) )\n",
      "Cell \u001b[0;32mIn[2], line 138\u001b[0m, in \u001b[0;36mget_lcc\u001b[0;34m(G)\u001b[0m\n\u001b[1;32m    136\u001b[0m largest_comp \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(nx\u001b[39m.\u001b[39mconnected_components(G), key\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(G) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mset\u001b[39m()\n\u001b[1;32m    137\u001b[0m \u001b[39m# Return the resulting graph\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m \u001b[39mreturn\u001b[39;00m nx\u001b[39m.\u001b[39;49mGraph(G\u001b[39m.\u001b[39;49msubgraph(largest_comp))\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/networkx/classes/graph.py:370\u001b[0m, in \u001b[0;36mGraph.__init__\u001b[0;34m(self, incoming_graph_data, **attr)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39m# attempt to load graph with data\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39mif\u001b[39;00m incoming_graph_data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 370\u001b[0m     convert\u001b[39m.\u001b[39;49mto_networkx_graph(incoming_graph_data, create_using\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    371\u001b[0m \u001b[39m# load graph attributes (must be after convert)\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mupdate(attr)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/networkx/convert.py:76\u001b[0m, in \u001b[0;36mto_networkx_graph\u001b[0;34m(data, create_using, multigraph_input)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(data, \u001b[39m\"\u001b[39m\u001b[39madj\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     75\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         result \u001b[39m=\u001b[39m from_dict_of_dicts(\n\u001b[1;32m     77\u001b[0m             data\u001b[39m.\u001b[39;49madj,\n\u001b[1;32m     78\u001b[0m             create_using\u001b[39m=\u001b[39;49mcreate_using,\n\u001b[1;32m     79\u001b[0m             multigraph_input\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mis_multigraph(),\n\u001b[1;32m     80\u001b[0m         )\n\u001b[1;32m     81\u001b[0m         \u001b[39m# data.graph should be dict-like\u001b[39;00m\n\u001b[1;32m     82\u001b[0m         result\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mupdate(data\u001b[39m.\u001b[39mgraph)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/networkx/convert.py:445\u001b[0m, in \u001b[0;36mfrom_dict_of_dicts\u001b[0;34m(d, create_using, multigraph_input)\u001b[0m\n\u001b[1;32m    443\u001b[0m                 seen\u001b[39m.\u001b[39madd((v, u))\n\u001b[1;32m    444\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 445\u001b[0m         G\u001b[39m.\u001b[39;49madd_edges_from(\n\u001b[1;32m    446\u001b[0m             ((u, v, data) \u001b[39mfor\u001b[39;49;00m u, nbrs \u001b[39min\u001b[39;49;00m d\u001b[39m.\u001b[39;49mitems() \u001b[39mfor\u001b[39;49;00m v, data \u001b[39min\u001b[39;49;00m nbrs\u001b[39m.\u001b[39;49mitems())\n\u001b[1;32m    447\u001b[0m         )\n\u001b[1;32m    448\u001b[0m \u001b[39mreturn\u001b[39;00m G\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/networkx/classes/graph.py:1016\u001b[0m, in \u001b[0;36mGraph.add_edges_from\u001b[0;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_edges_from\u001b[39m(\u001b[39mself\u001b[39m, ebunch_to_add, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mattr):\n\u001b[1;32m    962\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Add all the edges in ebunch_to_add.\u001b[39;00m\n\u001b[1;32m    963\u001b[0m \n\u001b[1;32m    964\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[39m    >>> G.add_edges_from(list((5, n) for n in G.nodes))\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1016\u001b[0m     \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m ebunch_to_add:\n\u001b[1;32m   1017\u001b[0m         ne \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(e)\n\u001b[1;32m   1018\u001b[0m         \u001b[39mif\u001b[39;00m ne \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/networkx/convert.py:446\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    443\u001b[0m                 seen\u001b[39m.\u001b[39madd((v, u))\n\u001b[1;32m    444\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m         G\u001b[39m.\u001b[39madd_edges_from(\n\u001b[0;32m--> 446\u001b[0m             ((u, v, data) \u001b[39mfor\u001b[39;00m u, nbrs \u001b[39min\u001b[39;00m d\u001b[39m.\u001b[39mitems() \u001b[39mfor\u001b[39;00m v, data \u001b[39min\u001b[39;00m nbrs\u001b[39m.\u001b[39mitems())\n\u001b[1;32m    447\u001b[0m         )\n\u001b[1;32m    448\u001b[0m \u001b[39mreturn\u001b[39;00m G\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/_collections_abc.py:910\u001b[0m, in \u001b[0;36mItemsView.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 910\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mapping:\n\u001b[1;32m    911\u001b[0m         \u001b[39myield\u001b[39;00m (key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mapping[key])\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/networkx/classes/coreviews.py:50\u001b[0m, in \u001b[0;36mAtlasView.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_atlas)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/networkx/classes/coreviews.py:281\u001b[0m, in \u001b[0;36mFilterAtlas.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m node_ok_shorter:\n\u001b[1;32m    280\u001b[0m     \u001b[39mreturn\u001b[39;00m (n \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mNODE_OK\u001b[39m.\u001b[39mnodes \u001b[39mif\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atlas)\n\u001b[0;32m--> 281\u001b[0m \u001b[39mreturn\u001b[39;00m (n \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_atlas \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mNODE_OK(n))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#n=100\n",
    "#p=0.1\n",
    "#k=5\n",
    "# G=nx.erdos_renyi_graph(n, p)\n",
    "#G = nx.watts_strogatz_graph(n, k, p)\n",
    "# nx.draw(G, with_labels=True)\n",
    "\n",
    "read_file = mmread('power-bcspwr10.mtx')\n",
    "G = nx.Graph(read_file)\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "n = G.number_of_nodes()\n",
    "\n",
    "def attack(G: nx.graph, percentage: float=0.1):\n",
    "    '''Attack the graph G with different attack strategies and plot the results.\n",
    "\n",
    "    Abstract:\n",
    "        1. take largest connected component\n",
    "        2. save lcc and diameter\n",
    "        3. attack the graph on a percentage basis\n",
    "        repeat 1-3 until graph is empty\n",
    "    '''\n",
    "    nodes_per_iteration = int(G.number_of_nodes() * percentage)\n",
    "    return\n",
    "\n",
    "def attack_random(G: nx.graph, nodes_per_iteration: int):\n",
    "    g1 = G.copy()\n",
    "    l1 = []\n",
    "    d1 = []\n",
    "    x1 = []\n",
    "    initial_nodes = g1.number_of_nodes()\n",
    "    print(\"g1\")\n",
    "    while g1.number_of_nodes() > 0:\n",
    "        print(g1.number_of_nodes())\n",
    "        g1 = get_lcc(g1)\n",
    "        l1.append( g1.number_of_nodes() )\n",
    "        d1.append( get_diameter(g1) )\n",
    "        g1 = remove_random_nodes(g1, nodes_per_iteration)\n",
    "        res = initial_nodes - g1.number_of_nodes()\n",
    "        x1.append( res/initial_nodes )\n",
    "\n",
    "def attack_degree(G: nx.graph, nodes_per_iteration: int):\n",
    "    g2 = G.copy()\n",
    "    l2 = []\n",
    "    d2 = []\n",
    "    x2 = []\n",
    "    initial_nodes = g2.number_of_nodes()\n",
    "    print(\"g2\")\n",
    "    while g2.number_of_nodes() > 0:\n",
    "        print(g2.number_of_nodes())\n",
    "        g2 = get_lcc(g2)\n",
    "        l2.append( g2.number_of_nodes() )\n",
    "        d2.append( get_diameter(g2) )\n",
    "        g2 = remove_highest_degree_node(g2, nodes_per_iteration)\n",
    "        res = initial_nodes - g2.number_of_nodes()\n",
    "        x2.append( res/initial_nodes )\n",
    "    # TODO: return values\n",
    "\n",
    "def attack_betweenness(G: nx.graph, nodes_per_iteration: int):\n",
    "    g3 = G.copy()\n",
    "    l3 = []\n",
    "    d3 = []\n",
    "    x3 = []\n",
    "    initial_nodes = g3.number_of_nodes()\n",
    "    print(\"g3\")\n",
    "    while g3.number_of_nodes() > 0:\n",
    "        print(g3.number_of_nodes())\n",
    "        g3 = get_lcc(g3)\n",
    "        l3.append( g3.number_of_nodes() )\n",
    "        d3.append( get_diameter(g3) )\n",
    "        g3 = remove_highest_betweenness_node(g3, nodes_per_iteration)\n",
    "        res = initial_nodes - g3.number_of_nodes()\n",
    "        x3.append( res/initial_nodes )\n",
    "    # TODO: return values\n",
    "    \n",
    "def attack_pagerank(G: nx.graph, nodes_per_iteration: int):\n",
    "    g4 = G.copy()\n",
    "    l4 = []\n",
    "    d4 = []\n",
    "    x4 = []\n",
    "    initial_nodes = g4.number_of_nodes()\n",
    "    print(\"g4\")\n",
    "    while g4.number_of_nodes() > 0:\n",
    "        print(g4.number_of_nodes())\n",
    "        g4 = get_lcc(g4)\n",
    "        l4.append( g4.number_of_nodes() )\n",
    "        d4.append( get_diameter(g4) )\n",
    "        g4 = remove_highest_pagerank_node(g4, nodes_per_iteration)\n",
    "        res = initial_nodes - g4.number_of_nodes()\n",
    "        x4.append( res/initial_nodes )\n",
    "    # TODO: return values\n",
    "\n",
    "def attack_closeness(G: nx.graph, nodes_per_iteration: int):\n",
    "    g5 = G.copy()\n",
    "    l5 = []\n",
    "    d5 = []\n",
    "    x5 = []\n",
    "    initial_nodes = g5.number_of_nodes()\n",
    "    print(\"g5\")\n",
    "    while g5.number_of_nodes() > 0:\n",
    "        print(g5.number_of_nodes())\n",
    "        g5 = get_lcc(g5)\n",
    "        l5.append( g5.number_of_nodes() )\n",
    "        d5.append( get_diameter(g5) )\n",
    "        g5 = remove_highest_closeness_node(g5, nodes_per_iteration)\n",
    "        res = initial_nodes - g5.number_of_nodes()\n",
    "        x5.append( res/initial_nodes )\n",
    "\n",
    "def plot_results(\n",
    "        x1:list, x2:list, x3:list, x4:list, x5:list,\n",
    "        l1:list, l2:list, l3:list, l4:list, l5:list,\n",
    "        d1:list, d2:list, d3:list, d4:list, d5:list):\n",
    "    plt.figure(figsize=(16,16), dpi=300)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.title('Largest connected component size vs percentage of nodes removed')\n",
    "    plt.plot(x1, l1, label='random')\n",
    "    plt.plot(x2, l2, label='highest degree')\n",
    "    plt.plot(x3, l3, label='highest betweenness')\n",
    "    plt.plot(x4, l4, label='highest pagerank')\n",
    "    plt.plot(x5, l5, label='highest closeness')\n",
    "    plt.xlabel('percentage of nodes removed')\n",
    "    plt.ylabel('giant component size')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.title('Diameter vs percentage of nodes removed')\n",
    "    plt.plot(x1, d1, label='random')\n",
    "    plt.plot(x2, d2, label='highest degree')\n",
    "    plt.plot(x3, d3, label='highest betweenness')\n",
    "    plt.plot(x4, d4, label='highest pagerank')\n",
    "    plt.plot(x5, d5, label='highest closeness')\n",
    "    plt.xlabel('percentage of nodes removed')\n",
    "    plt.ylabel('diameter')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "attack(G, 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "def notify(title, text):\n",
    "    os.system(\"\"\"\n",
    "              osascript -e 'display notification \"{}\" with title \"{}\"'\n",
    "              \"\"\".format(text, title))\n",
    "\n",
    "notify(\"Done\", \"Python completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot G\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title('G')\n",
    "nx.draw(G, with_labels=False, node_size=10, width=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis Before the Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_diameter=[]\n",
    "rnd_avg_degree=[]\n",
    "highest_degree_diameter=[]\n",
    "highest_degree_avg_degree=[]\n",
    "\n",
    "n=100\n",
    "p=0.1\n",
    "G=nx.erdos_renyi_graph(n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(G):\n",
    "    print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "   # print(f\"Density: {nx.density(G)}\")\n",
    "   # print(f\"Transitivity: {nx.transitivity(G)}\")\n",
    "    print(f\"Max Degree: {max(dict(G.degree()).values())}\")\n",
    "    print(f\"Min Degree: {min(dict(G.degree()).values())}\")\n",
    "    print(f\"Average Degree: {np.mean(list(dict(G.degree()).values()))}\")\n",
    "    rnd_avg_degree.append(np.mean(list(dict(G.degree()).values())))\n",
    "    highest_degree_avg_degree.append(np.mean(list(dict(G.degree()).values())))\n",
    "    print(f\"Number of components:{nx.number_connected_components(G)}\")\n",
    "    print(f\"Assortativity: {nx.degree_assortativity_coefficient(G)}\")\n",
    "    betwenness_centrality = nx.betweenness_centrality(G)\n",
    "    closeness_centrality = nx.closeness_centrality(G)\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    print(f\"Betweenness centrality max:{max(betwenness_centrality.values())}\")\n",
    "    print(f\"Closeness centrality max:{max(closeness_centrality.values())}\")\n",
    "    print(f\"Degree centrality max:{max(degree_centrality.values())}\")\n",
    "\n",
    "    if(nx.is_connected(G)):\n",
    "        print(\"Graph is connected\")\n",
    "        print(f\"Diameter: {nx.diameter(G)}\")\n",
    "        highest_degree_diameter.append(nx.diameter(G))\n",
    "        rnd_diameter.append(nx.diameter(G))\n",
    "    else:\n",
    "        print(\"Graph is not connected\")\n",
    "        G=G.subgraph(max(nx.connected_components(G), key=len))\n",
    "        highest_degree_diameter.append(nx.diameter(G))\n",
    "        rnd_diameter.append(nx.diameter(G))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"Betweenness distribution\")\n",
    "    plt.hist(betwenness_centrality.values(), bins=100, log=True)\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.title(\"Closeness distribution\")\n",
    "    plt.hist(closeness_centrality.values(), bins=100)\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.title(\"Degree centrality distribution\")\n",
    "    plt.hist(degree_centrality.values())\n",
    "    \n",
    "    plt.show()\n",
    "    fig, ax = plt.subplots(figsize=(5,3))\n",
    "\n",
    "    degree_sequence = sorted((d for n, d in G.degree()), reverse=True)\n",
    "    dmax = max(degree_sequence)\n",
    "    plt.bar(*np.unique(degree_sequence, return_counts=True))\n",
    "    #average degree vicino  alla mediana: 7 -> non è scale free\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_rand=G.copy()\n",
    "measure(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.0001\n",
    "val_p=[]\n",
    "while G.number_of_nodes() > 1:\n",
    "    val_p.append(p)\n",
    "    # Calculate the number of nodes to remove\n",
    "    num_nodes = len(G.nodes())\n",
    "    nodes_to_remove = round(num_nodes * p)\n",
    "\n",
    "    # Randomly select nodes to remove\n",
    "    nodes = list(G.nodes())\n",
    "    nodes_to_remove = random.sample(nodes, nodes_to_remove)\n",
    "\n",
    "    # Remove the selected nodes from the graph\n",
    "    G.remove_nodes_from(nodes_to_remove)\n",
    "    measure(G)\n",
    "    p+=0.1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot distribution of Diameter and Average degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Average degree\")\n",
    "#x labels = val_p normalizzati\n",
    "\n",
    "plt.xlabel(\"p\")\n",
    "plt.ylabel(\"Average degree\")\n",
    "plt.plot(rnd_avg_degree)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Diameter\")\n",
    "plt.xlabel(\"p\")\n",
    "plt.ylabel(\"Diameter\")\n",
    "plt.plot(rnd_diameter)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(val_p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
